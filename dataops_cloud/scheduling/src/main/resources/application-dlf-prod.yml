#server:
#  port: 18002
spring:
  application:
    name: scheduling
  cloud:
    nacos:
      discovery:
        server-addr: 10.23.71.70:8848
  kafka:
    bootstrap-servers: 10.23.71.70:9092
    #consumer   配置
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.IntegerDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      value-deserializer: com.cuit.common.utils.Decoding
      group-id: springboot-consumer01
      #如果在Kafka中找不到当前消费者的偏移量则直接将偏移量重置为最早的
      auto-offset-reset: earliest
      #消费者的偏移量是自动提交还是手动提交
      enable-auto-commit: true
      #多长时间提交一次偏移量
      auto-commit-interval: 1000
      properties:
        request:
          timeout:
            ms: 30000000
        fetch:
          max:
            wait:
              ms: 3000000
        spring:
          json:
            trusted:
              packages: com.artisan.springkafka.domain
    listener:
      ack-count: 1
#      ack-mode: record #每处理一条commit一次
##dubbo的相关配置
#dubbo:
#  scan:
#    base-packages: com.cuit.scheduling.service
#  protocol:
#    name: dubbo #    传输协议的名称：dubbo rmi hessian webservice
#    port: -1  #-1表示端口随机
#  registry:
#    address: spring-cloud://10.23.71.70  #注册中心配置，用于配置连接注册中心相关信息


data:
  save: /Users/dailinfeng/Desktop/dataops/result
  dataPath: /Users/dailinfeng/Desktop/dataops/data
  serverBaseUrl: http://10.23.71.70:18002/result #结果元数据文件下载连接

forest:
  variables:
    baseUrl: http://10.23.71.70:8000 #文件下载和远程调用的url
#    baseUrl: http://127.0.0.1:8000
    notifyUrl: http://10.23.71.70:5700   #qq 机器人的url